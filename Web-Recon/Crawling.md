1. Crawling, often called `spidering`, is the `automated process of systematically browsing the World Wide Web

#### How web Crawler Work

Web Crawler are straightforward yet powerful.
	1. It start with the seed URL, which is the initial point to crawl.
	2. Crawler fetches this page, parser its content and extracts all its link.
	3. Then it adds the links to a queue and crawls them.

###### Types of Crawlers:

1. Breadth-First Crawling: Crawl prioritize depends on size.

2. Depth-First Crawling: Crawl prioritize depends on depth. 

##### Extracting Valuable Information

1. Links
2. Comments
3. Metadata
4. Sensitive Files
